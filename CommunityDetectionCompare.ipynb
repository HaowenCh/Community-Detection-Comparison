{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edd6ea25",
   "metadata": {},
   "source": [
    "### Import Python Packages to start reproducing results with ABCD graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "0fc7b281",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ignore user warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "30d959c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### import packages\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from sklearn.metrics import adjusted_mutual_info_score\n",
    "### For MR and MV\n",
    "import pygenstability as pgs\n",
    "from pygenstability import plotting as pgs_plotting\n",
    "### For Bayan\n",
    "import bayanpy as bp\n",
    "### For Louvain, Leiden, Paris, Combo\n",
    "from cdlib import algorithms\n",
    "\n",
    "### Seed the random number generator\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3f9a6e",
   "metadata": {},
   "source": [
    "### Define Algorithms calculating AMI score for each ABCD Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "4cd52656",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run PyGenStability's Markov Stability with automated optimal scale selection using NVI\n",
    "def MV_Run(G):\n",
    "    ### Convert NetworkX graph into csgraph for PyGenStability to use\n",
    "    A = nx.to_scipy_sparse_array(G)\n",
    "\n",
    "    ### Run PyGenStability's Markov Stability with automated optimal scale selection using NVI\n",
    "    MV_results = pgs.run(\n",
    "        A,\n",
    "        n_scale=50,\n",
    "        constructor='continuous_combinatorial',\n",
    "        with_optimal_scales=True,\n",
    "        n_workers=4,\n",
    "        tqdm_disable=True\n",
    "    )\n",
    "\n",
    "    ### Selected the partition with the minimum NVI\n",
    "    ### Initialize the minimum NVI to 1 since the max NVI is 1\n",
    "    min_NVI = 1\n",
    "    min_NVI_partition = MV_results['selected_partitions'][0]\n",
    "    for i in MV_results['selected_partitions']:\n",
    "        min_NVI = min(min_NVI, MV_results['NVI'][i])\n",
    "        if MV_results['NVI'][i] == min_NVI:\n",
    "            min_NVI_partition = i\n",
    "\n",
    "    ### Convert the best partitions to numpy array\n",
    "    partition_pred = np.array(MV_results['community_id'][min_NVI_partition])\n",
    "\n",
    "    ### Read the community labels from the networkX graph and create the true partition array\n",
    "    community_dict = {}\n",
    "    index = 0\n",
    "    for node in G.nodes:\n",
    "        if G.nodes[node]['community'] not in community_dict.values():\n",
    "            community_dict[index] = G.nodes[node]['community']\n",
    "            index += 1\n",
    "\n",
    "    partition_true = np.array([key for node in G.nodes for key, value in community_dict.items() if G.nodes[node]['community'] == value])\n",
    "    ami_score = adjusted_mutual_info_score(partition_true, partition_pred)\n",
    "            \n",
    "    return ami_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "95cc8006",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run PyGenStability's Markov Stability with a random partition\n",
    "def MR_Run(G):\n",
    "    ### Convert NetworkX graph into csgraph for PyGenStability to use\n",
    "    A = nx.to_scipy_sparse_array(G)\n",
    "\n",
    "    ### Run PyGenStability's Markov Stability with automated optimal scale selection using NVI\n",
    "    MV_results = pgs.run(\n",
    "        A,\n",
    "        n_scale=50,\n",
    "        constructor='continuous_combinatorial',\n",
    "        with_optimal_scales=True,\n",
    "        n_workers=4,\n",
    "        tqdm_disable=True\n",
    "    )\n",
    "\n",
    "    ### Randomly select a partition from 0-49 because the n_scale is 50\n",
    "    random_partition = np.random.randint(0, 50)\n",
    "\n",
    "    ### Convert the best partitions to numpy array\n",
    "    partition_pred = np.array(MV_results['community_id'][random_partition])\n",
    "\n",
    "    ### Read the community labels from the networkX graph and create the true partition array\n",
    "    community_dict = {}\n",
    "    index = 0\n",
    "    for node in G.nodes:\n",
    "        if G.nodes[node]['community'] not in community_dict.values():\n",
    "            community_dict[index] = G.nodes[node]['community']\n",
    "            index += 1\n",
    "\n",
    "    partition_true = np.array([key for node in G.nodes for key, value in community_dict.items() if G.nodes[node]['community'] == value])\n",
    "    ami_score = adjusted_mutual_info_score(partition_true, partition_pred)\n",
    "            \n",
    "    return ami_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "1681045c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run Bayan to find partition within 1% of the maximum modularity with a execution time limit of 60 seconds and resolution parameter of 1\n",
    "def Bayan_Run(G):\n",
    "    \n",
    "    modularity, optimality_gap, community, modeling_time, solve_time = bp.bayan(G, threshold=0.01, time_allowed=60, resolution=1)\n",
    "\n",
    "    ### Read the community labels from the networkX graph and create the true partition array\n",
    "    community_dict = {}\n",
    "    index = 0\n",
    "    for node in G.nodes:\n",
    "        if G.nodes[node]['community'] not in community_dict.values():\n",
    "            community_dict[index] = G.nodes[node]['community']\n",
    "            index += 1\n",
    "\n",
    "    partition_true = np.array([key for node in G.nodes for key, value in community_dict.items() if G.nodes[node]['community'] == value])\n",
    "\n",
    "    ### Create the predicted partition array, since the community labels are not continuous, use integer type\n",
    "    partition_pred = np.zeros(len(G.nodes), dtype=int)\n",
    "    for i in range(len(community)):\n",
    "        for node in G.nodes:\n",
    "            if node in community[i]:\n",
    "                partition_pred[int(node)] = i\n",
    "\n",
    "    ### Calculate the AMI score\n",
    "    ami_score = adjusted_mutual_info_score(partition_true, partition_pred)\n",
    "    return ami_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "d96eb03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run Louvain's algorithm to find partition\n",
    "def Louvain_Run(G):\n",
    "    _cdlib_global_seed = 42\n",
    "    communities = algorithms.louvain(G, randomize=42)\n",
    "\n",
    "    ### Create the predicted partition array from Louvain\n",
    "    partition_pred = np.zeros(len(G.nodes), dtype=int)\n",
    "    for index, community in enumerate(communities.communities):\n",
    "        for node in community:\n",
    "            partition_pred[int(node)] = index\n",
    "\n",
    "\n",
    "    ### Read the community labels from the networkX graph and create the true partition array\n",
    "    community_dict = {}\n",
    "    index = 0\n",
    "    for node in G.nodes:\n",
    "        if G.nodes[node]['community'] not in community_dict.values():\n",
    "            community_dict[index] = G.nodes[node]['community']\n",
    "            index += 1\n",
    "\n",
    "    partition_true = np.array([key for node in G.nodes for key, value in community_dict.items() if G.nodes[node]['community'] == value])\n",
    "\n",
    "    ### Calculate the AMI score\n",
    "    ami_score = adjusted_mutual_info_score(partition_true, partition_pred)\n",
    "    \n",
    "    return ami_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "87753aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run Leiden's algorithm to find partition\n",
    "### Since in CDLib 0.2.6, the Leiden algorithm does not have a seed parameter, and it is utilizing leidenalg package to \n",
    "### perform the Leiden algorithm which is not deterministic and is taking random seed as a parameter, \n",
    "### and there is no global seed for leidenalg package,\n",
    "### therefore, by using CDLib 0.2.6, there is no way to fix the seed for the Leiden algorithm unless we use leidenalg package directly.\n",
    "def Leiden_Run(G):\n",
    "    communities = algorithms.leiden(G)\n",
    "\n",
    "    ### Create the predicted partition array from Leiden\n",
    "    partition_pred = np.zeros(len(G.nodes), dtype=int)\n",
    "    for index, community in enumerate(communities.communities):\n",
    "        for node in community:\n",
    "            partition_pred[int(node)] = index\n",
    "\n",
    "    ### Read the community labels from the networkX graph and create the true partition array\n",
    "    community_dict = {}\n",
    "    index = 0\n",
    "    for node in G.nodes:\n",
    "        if G.nodes[node]['community'] not in community_dict.values():\n",
    "            community_dict[index] = G.nodes[node]['community']\n",
    "            index += 1\n",
    "\n",
    "    partition_true = np.array([key for node in G.nodes for key, value in community_dict.items() if G.nodes[node]['community'] == value])\n",
    "\n",
    "    ### Calculate the AMI score\n",
    "    ami_score = adjusted_mutual_info_score(partition_true, partition_pred)\n",
    "    \n",
    "    return ami_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "74721117",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run Paris's algorithm to find partition\n",
    "def Paris_Run(G):\n",
    "    communities = algorithms.paris(G)\n",
    "\n",
    "    ### Create the predicted partition array from Paris\n",
    "    partition_pred = np.zeros(len(G.nodes), dtype=int)\n",
    "    for index, community in enumerate(communities.communities):\n",
    "        for node in community:\n",
    "            partition_pred[int(node)] = index\n",
    "\n",
    "    ### Read the community labels from the networkX graph and create the true partition array\n",
    "    community_dict = {}\n",
    "    index = 0\n",
    "    for node in G.nodes:\n",
    "        if G.nodes[node]['community'] not in community_dict.values():\n",
    "            community_dict[index] = G.nodes[node]['community']\n",
    "            index += 1\n",
    "\n",
    "    partition_true = np.array([key for node in G.nodes for key, value in community_dict.items() if G.nodes[node]['community'] == value])\n",
    "\n",
    "    ### Calculate the AMI score\n",
    "    ami_score = adjusted_mutual_info_score(partition_true, partition_pred)\n",
    "\n",
    "    return ami_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "a0c54b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run Combo algorithm to find partition\n",
    "def Combo_Run(G):\n",
    "    communities = algorithms.pycombo(G)\n",
    "\n",
    "    ### Create the predicted partition array from Combo\n",
    "    partition_pred = np.zeros(len(G.nodes), dtype=int)\n",
    "    for index, community in enumerate(communities.communities):\n",
    "        for node in community:\n",
    "            partition_pred[int(node)] = index\n",
    "\n",
    "    ### Read the community labels from the networkX graph and create the true partition array\n",
    "    community_dict = {}\n",
    "    index = 0\n",
    "    for node in G.nodes:\n",
    "        if G.nodes[node]['community'] not in community_dict.values():\n",
    "            community_dict[index] = G.nodes[node]['community']\n",
    "            index += 1\n",
    "\n",
    "    partition_true = np.array([key for node in G.nodes for key, value in community_dict.items() if G.nodes[node]['community'] == value])\n",
    "\n",
    "    ### Calculate the AMI score\n",
    "    ami_score = adjusted_mutual_info_score(partition_true, partition_pred)\n",
    "\n",
    "    return ami_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "a005acac",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run Infomap to find partition\n",
    "def Infomap_Run(G):\n",
    "    communities = algorithms.infomap(G)\n",
    "\n",
    "    ### Create the predicted partition array from Belief\n",
    "    partition_pred = np.zeros(len(G.nodes), dtype=int)\n",
    "    for index, community in enumerate(communities.communities):\n",
    "        for node in community:\n",
    "            partition_pred[int(node)] = index\n",
    "\n",
    "    ### Read the community labels from the networkX graph and create the true partition array\n",
    "    community_dict = {}\n",
    "    index = 0\n",
    "    for node in G.nodes:\n",
    "        if G.nodes[node]['community'] not in community_dict.values():\n",
    "            community_dict[index] = G.nodes[node]['community']\n",
    "            index += 1\n",
    "\n",
    "    partition_true = np.array([key for node in G.nodes for key, value in community_dict.items() if G.nodes[node]['community'] == value])\n",
    "\n",
    "    ### Calculate the AMI score\n",
    "    ami_score = adjusted_mutual_info_score(partition_true, partition_pred)\n",
    "\n",
    "    return ami_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1bd8f8",
   "metadata": {},
   "source": [
    "### Now we start running test for ABCD graphs with mixing parameter = 0.1, 0.3, 0.5, 0.7, 0.9\n",
    "### And calculate the average AMI scores for each algorithm under different mixing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa37266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running algorithms for mixing parameter 0.1 ===\n",
      "MV has no results for this mixing parameter\n",
      "MR has no results for this mixing parameter\n",
      "Bayan has no results for this mixing parameter\n",
      "Louvain has no results for this mixing parameter\n",
      "Leiden has no results for this mixing parameter\n",
      "Paris has no results for this mixing parameter\n",
      "Combo has no results for this mixing parameter\n",
      "Infomap under xi = 0.1: 0.843980\n",
      "\n",
      "=== Running algorithms for mixing parameter 0.3 ===\n",
      "MV has no results for this mixing parameter\n",
      "MR has no results for this mixing parameter\n",
      "Bayan has no results for this mixing parameter\n",
      "Louvain has no results for this mixing parameter\n",
      "Leiden has no results for this mixing parameter\n",
      "Paris has no results for this mixing parameter\n",
      "Combo has no results for this mixing parameter\n",
      "Infomap under xi = 0.3: 0.702958\n",
      "\n",
      "=== Running algorithms for mixing parameter 0.5 ===\n",
      "MV has no results for this mixing parameter\n",
      "MR has no results for this mixing parameter\n",
      "Bayan has no results for this mixing parameter\n",
      "Louvain has no results for this mixing parameter\n",
      "Leiden has no results for this mixing parameter\n",
      "Paris has no results for this mixing parameter\n",
      "Combo has no results for this mixing parameter\n",
      "Infomap under xi = 0.5: 0.243178\n",
      "\n",
      "=== Running algorithms for mixing parameter 0.7 ===\n",
      "MV has no results for this mixing parameter\n",
      "MR has no results for this mixing parameter\n",
      "Bayan has no results for this mixing parameter\n",
      "Louvain has no results for this mixing parameter\n",
      "Leiden has no results for this mixing parameter\n",
      "Paris has no results for this mixing parameter\n",
      "Combo has no results for this mixing parameter\n",
      "Infomap under xi = 0.7: 0.056465\n",
      "\n",
      "=== Running algorithms for mixing parameter 0.9 ===\n",
      "MV has no results for this mixing parameter\n",
      "MR has no results for this mixing parameter\n",
      "Bayan has no results for this mixing parameter\n",
      "Louvain has no results for this mixing parameter\n",
      "Leiden has no results for this mixing parameter\n",
      "Paris has no results for this mixing parameter\n",
      "Combo has no results for this mixing parameter\n",
      "Infomap under xi = 0.9: 0.009189\n"
     ]
    }
   ],
   "source": [
    "def run_algorithms_on_ABCD(mixing_parameter):\n",
    "    \"\"\"\n",
    "    Run community detection algorithms on ABCD graphs with specified mixing parameter\n",
    "    \n",
    "    Args:\n",
    "        mixing_parameter (float): The mixing parameter value (e.g. 0.1)\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing AMI scores for each graph and for each algorithm\n",
    "    \"\"\"\n",
    "    ### Initialize results storage\n",
    "    results = {\n",
    "        'MV': [],\n",
    "        'MR': [], \n",
    "        'Bayan': [],\n",
    "        'Louvain': [],\n",
    "        'Leiden': [],\n",
    "        'Paris': [],\n",
    "        'Combo': [],\n",
    "        'Infomap': []\n",
    "    }\n",
    "\n",
    "    ### Loop through all ABCD graphs from 0 to 99\n",
    "    for graph_num in range(100):\n",
    "        \n",
    "        ### Load the graph\n",
    "        gml_path = f'./FigShare_repo/Random_graph_data/ABCD_graphs/xi_{mixing_parameter}/ABCD_{graph_num}.gml'\n",
    "        \n",
    "        ### Check if the file exists\n",
    "        if not os.path.exists(gml_path):\n",
    "            print(f\"File {gml_path} not found, skipping...\")\n",
    "            continue\n",
    "                \n",
    "        G = nx.read_gml(gml_path)\n",
    "\n",
    "        ### Run algorithms and store results\n",
    "        results['MV'].append(MV_Run(G))\n",
    "        results['MR'].append(MR_Run(G))\n",
    "        results['Bayan'].append(Bayan_Run(G))\n",
    "        results['Louvain'].append(Louvain_Run(G))\n",
    "        if (not (mixing_parameter == 0.5 and graph_num == 2)) and (not (mixing_parameter == 0.7 and graph_num == 25)):\n",
    "            results['Leiden'].append(Leiden_Run(G))\n",
    "        results['Paris'].append(Paris_Run(G))\n",
    "        results['Combo'].append(Combo_Run(G))\n",
    "        results['Infomap'].append(Infomap_Run(G))\n",
    "        \n",
    "    return results\n",
    "\n",
    "### Run algorithms for different mixing parameters\n",
    "mixing_parameters = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "for mixing_parameter in mixing_parameters:\n",
    "    print(f\"\\n=== Running algorithms for mixing parameter {mixing_parameter} ===\")\n",
    "    results = run_algorithms_on_ABCD(mixing_parameter)\n",
    "    ### Calculate average AMI scores for each algorithm\n",
    "    for algorithm in results:\n",
    "        ### Check if the algorithm in results is not empty array\n",
    "        if not results[algorithm]:\n",
    "            print(f\"{algorithm} has no results for this mixing parameter\")\n",
    "            continue\n",
    "        ### Output the average AMI score for the algorithm for this mixing parameter\n",
    "        average_ami = sum(results[algorithm]) / len(results[algorithm])\n",
    "        print(f\"{algorithm} under xi = {mixing_parameter}: {average_ami:.6f}\")\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
